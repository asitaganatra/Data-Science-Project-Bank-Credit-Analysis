{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902d5ed6",
   "metadata": {},
   "source": [
    "# Bank Credit Analysis Project - Report Visualizations\n",
    "\n",
    "This notebook generates visualizations and metrics for the project report. It includes:\n",
    "1. Model Performance Analysis\n",
    "2. Clustering Visualizations\n",
    "3. Deep Learning Training Curves\n",
    "4. Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf43d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import silhouette_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import joblib\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display versions for reproducibility\n",
    "print(f\"Python version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab39c0",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "First, we'll load the dataset and prepare it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('cleaned_bank_credit_data.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nSample Data:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f57f05",
   "metadata": {},
   "source": [
    "## 2. Model Performance Analysis\n",
    "\n",
    "Let's analyze the performance of our various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "models = {\n",
    "    'Linear Regression (Amount)': joblib.load('bank_credit_model.joblib'),\n",
    "    'Random Forest (Amount)': joblib.load('rf_amount_model.joblib'),\n",
    "    'Linear Regression (Accounts)': joblib.load('account_prediction_model.joblib'),\n",
    "    'Random Forest (Accounts)': joblib.load('rf_accounts_model.joblib')\n",
    "}\n",
    "\n",
    "# Prepare features\n",
    "amount_features = ['region', 'population_group', 'bank_group', 'occupation_group', 'year', 'no_of_accounts']\n",
    "account_features = ['region', 'population_group', 'bank_group', 'occupation_group', 'year', 'credit_limit']\n",
    "\n",
    "# Calculate R² scores\n",
    "amount_scores = {\n",
    "    'Linear Regression': models['Linear Regression (Amount)'].score(df[amount_features], np.log1p(df['amount_outstanding'])),\n",
    "    'Random Forest': models['Random Forest (Amount)'].score(df[amount_features], np.log1p(df['amount_outstanding']))\n",
    "}\n",
    "\n",
    "account_scores = {\n",
    "    'Linear Regression': models['Linear Regression (Accounts)'].score(df[account_features], np.log1p(df['no_of_accounts'])),\n",
    "    'Random Forest': models['Random Forest (Accounts)'].score(df[account_features], np.log1p(df['no_of_accounts']))\n",
    "}\n",
    "\n",
    "# Create bar plot\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Amount Prediction', x=list(amount_scores.keys()), y=list(amount_scores.values())),\n",
    "    go.Bar(name='Account Prediction', x=list(account_scores.keys()), y=list(account_scores.values()))\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Performance Comparison (R² Score)',\n",
    "    xaxis_title='Model Type',\n",
    "    yaxis_title='R² Score',\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc26083",
   "metadata": {},
   "source": [
    "## 3. Clustering Analysis\n",
    "\n",
    "Let's analyze the clustering results with different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a030f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import clustering module\n",
    "import clustering\n",
    "\n",
    "# Features for clustering\n",
    "features = ['credit_limit', 'amount_outstanding', 'no_of_accounts']\n",
    "\n",
    "# Run different clustering algorithms\n",
    "algorithms = {\n",
    "    'KMeans': {'algorithm': 'KMeans', 'params': {'n_clusters': 4}},\n",
    "    'DBSCAN': {'algorithm': 'DBSCAN', 'params': {'eps': 0.5, 'min_samples': 5}},\n",
    "    'Agglomerative': {'algorithm': 'Agglomerative', 'params': {'n_clusters': 4}}\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, config in algorithms.items():\n",
    "    results[name] = clustering.run_clustering(df, features, \n",
    "                                           algorithm=config['algorithm'],\n",
    "                                           params=config['params'])\n",
    "\n",
    "# Create visualization of clustering results\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, (name, result) in enumerate(results.items(), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    plt.scatter(result['X_pca'][:, 0], result['X_pca'][:, 1], c=result['labels'], cmap='tab10')\n",
    "    plt.title(f'{name}\\nSilhouette Score: {result[\"metrics\"][\"silhouette\"]:.3f}')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print cluster sizes\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name} Cluster Sizes:\")\n",
    "    unique, counts = np.unique(result['labels'], return_counts=True)\n",
    "    for cluster, count in zip(unique, counts):\n",
    "        print(f\"Cluster {cluster}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeef61c",
   "metadata": {},
   "source": [
    "## 4. Deep Learning Analysis\n",
    "\n",
    "Let's analyze the performance of our deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and train autoencoder\n",
    "import deep_learning\n",
    "\n",
    "# Select features for autoencoder\n",
    "features = ['credit_limit', 'amount_outstanding', 'no_of_accounts']\n",
    "X = df[features].values\n",
    "\n",
    "# Create and train autoencoder\n",
    "dl_model = deep_learning.DeepLearningModel()\n",
    "dl_model.create_autoencoder(input_dim=len(features), encoding_dim=2)\n",
    "dl_model.train(X, epochs=50)\n",
    "\n",
    "# Get the training history\n",
    "history = dl_model.history.history\n",
    "\n",
    "# Plot training curves\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history['loss'], name='Training Loss'))\n",
    "fig.add_trace(go.Scatter(y=history['val_loss'], name='Validation Loss'))\n",
    "fig.update_layout(\n",
    "    title='Autoencoder Training Progress',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss',\n",
    "    showlegend=True\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Get encoded representation\n",
    "encoded_data = dl_model.get_embeddings(X)\n",
    "\n",
    "# Plot encoded data\n",
    "fig = px.scatter(\n",
    "    x=encoded_data[:, 0],\n",
    "    y=encoded_data[:, 1],\n",
    "    color=df['bank_group'],\n",
    "    title='2D Encoded Representation by Bank Group'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c50a99",
   "metadata": {},
   "source": [
    "## 5. Save Visualizations\n",
    "\n",
    "Save the visualizations for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2eb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create report figures directory\n",
    "import os\n",
    "os.makedirs('report_figures', exist_ok=True)\n",
    "\n",
    "# Save model performance plot\n",
    "fig_performance = go.Figure(data=[\n",
    "    go.Bar(name='Amount Prediction', x=list(amount_scores.keys()), y=list(amount_scores.values())),\n",
    "    go.Bar(name='Account Prediction', x=list(account_scores.keys()), y=list(account_scores.values()))\n",
    "])\n",
    "fig_performance.write_html(\"report_figures/model_performance.html\")\n",
    "\n",
    "# Save clustering plots\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, (name, result) in enumerate(results.items(), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    plt.scatter(result['X_pca'][:, 0], result['X_pca'][:, 1], c=result['labels'], cmap='tab10')\n",
    "    plt.title(f'{name}\\nSilhouette Score: {result[\"metrics\"][\"silhouette\"]:.3f}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('report_figures/clustering_comparison.png')\n",
    "\n",
    "# Save autoencoder plots\n",
    "fig_training = go.Figure()\n",
    "fig_training.add_trace(go.Scatter(y=history['loss'], name='Training Loss'))\n",
    "fig_training.add_trace(go.Scatter(y=history['val_loss'], name='Validation Loss'))\n",
    "fig_training.write_html(\"report_figures/autoencoder_training.html\")\n",
    "\n",
    "print(\"All visualizations have been saved to the 'report_figures' directory.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
